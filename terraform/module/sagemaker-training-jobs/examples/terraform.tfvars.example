# SageMaker Training Jobs Module Configuration Example
# Copy this file to terraform.tfvars and customize for your environment

# Project Configuration
project_name        = "ml-pipeline"
environment         = "staging"
bucket_name_suffix  = "your-suffix"  # Replace with your unique suffix

# Training Job Configuration
training_image              = "763104351884.dkr.ecr.us-east-1.amazonaws.com/sklearn-learn:1.0-1-cpu-py3"  # Built-in SageMaker image
training_job_name_prefix    = "daily-training"
training_input_mode         = "File"

# Instance Configuration
instance_type       = "ml.m5.large"
instance_count      = 1
volume_size_gb      = 30
max_runtime_seconds = 3600  # 1 hour

# Data Configuration
input_data_config = [
  {
    ChannelName = "training"
    DataSource = {
      S3DataSource = {
        S3DataType             = "S3Prefix"
        S3Uri                  = "s3://your-ml-bucket/training-data/"
        S3DataDistributionType = "FullyReplicated"
      }
    }
    ContentType     = "text/csv"
    CompressionType = "None"
    InputMode       = "File"
  }
]

output_data_s3_path = "s3://your-ml-bucket/model-outputs/"
s3_bucket_arn       = "arn:aws:s3:::your-ml-bucket"

# Scheduling Configuration
enable_scheduling   = true
schedule_expression = "cron(0 2 * * ? *)"  # Daily at 2 AM UTC
schedule_enabled    = true

# MLflow Integration
mlflow_tracking_server_arn = "arn:aws:sagemaker:us-east-1:123456789012:mlflow-tracking-server/your-mlflow-server"
mlflow_tracking_uri        = "https://mlflow.us-east-1.amazonaws.com/your-mlflow-server"
enable_mlflow_integration  = true

# Hyperparameters
hyperparameters = {
  max_depth    = "5"
  n_estimators = "100"
  random_state = "42"
}

# Environment Variables
environment_variables = {
  MODEL_NAME = "example-model"
  VERSION    = "1.0"
  LOG_LEVEL  = "INFO"
}

# Cost Optimization (Optional)
enable_spot_training = false
# checkpoint_config = {
#   S3Uri     = "s3://your-ml-bucket/checkpoints/"
#   LocalPath = "/opt/ml/checkpoints"
# }

# Advanced Configuration (Optional)
enable_custom_launcher  = false
enable_network_isolation = false

# vpc_config = {
#   SecurityGroupIds = ["sg-12345678"]
#   Subnets          = ["subnet-12345678", "subnet-87654321"]
# }

# Monitoring (Optional)
# profiler_config = {
#   S3OutputPath                    = "s3://your-ml-bucket/profiler/"
#   ProfilingIntervalInMilliseconds = 500
# }

# debugger_hook_config = {
#   S3OutputPath = "s3://your-ml-bucket/debugger/"
#   LocalPath    = "/opt/ml/output/tensors"
# }

# Tags
tags = {
  Team               = "ML-Engineering"
  Environment        = "staging"
  Project            = "ml-pipeline"
  CostCenter         = "Engineering"
  DataClassification = "Internal"
}
